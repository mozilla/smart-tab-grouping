{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1c265b1-dd3c-4a18-abfc-bd04630ab19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TUNING_DATA_PATHS = [\"topic/topic_topic_fine_tuning_data__common_crawl_2025-02-23_08-18__filtered.csv\",\n",
    "                     \"topic/topic_topic_fine_tuning_data__2025-02-21_16-50__filtered.csv\"]  # \"topic/topic_fine_tuning_data_extractive_2_15.csv\"  # \"topic/topic_fine_tuning_data_guided__02_11_processed.csv\"\n",
    "TUNING_DATA_PATHS_WITH_NONE = [\"topic/fine_tuning_data__with_none__common_crawl_2025-02-23_08-18.csv\",\n",
    "                               \"topic/common_corpus_noise_none_3_12.csv\",\n",
    "                               \"topic/search_simplified.csv\"\n",
    "                               ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d12430df-f819-496e-bad4-d0e3fb72b216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Rrando/Documents/GitHub/smart-tab-grouping/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a9e1bfa-963b-451c-8c80-3af984a44077",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9784f84-b743-49fe-a19c-d887c7195a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAB_GROUPING_BUCKET_NAME = \"stage-fx-tab-grouping\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b522f4b-5cc4-4756-bb34-11c165e36dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/Rrando/Documents/GitHub/smart-tab-grouping/src\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f67d3bee-36ba-47f3-baed-5e49f64f9d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.secrets import load_env\n",
    "from util.storage import download_bucket_to_file, download_bucket_to_csv\n",
    "from util.shorten_topic_length import ShortenTopicLength\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8aeb744-69f1-41da-b080-5e82dd649d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1adcc65-2f5e-495c-87bb-a2d0c95cfaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rrando/Documents/GitHub/smart-tab-grouping/.venv/lib/python3.11/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded secrets from moz-fx-mozsoc-ml-nonprod\n",
      "Loading env from .env\n"
     ]
    }
   ],
   "source": [
    "load_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f01a4034-d33b-4986-bddf-f88a184fd830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7bf7a2e-29b6-4a1d-8b9a-c77a9ed04894",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE_TRAINING_DATA_SET_INDEX = 1\n",
    "local_filename = \"tuning_data.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67ed8bab-fe0f-403c-85f8-042c897aacad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using training files ['topic/fine_tuning_data__with_none__common_crawl_2025-02-23_08-18.csv', 'topic/common_corpus_noise_none_3_12.csv', 'topic/search_simplified.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rrando/Documents/GitHub/smart-tab-grouping/.venv/lib/python3.11/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/Users/Rrando/Documents/GitHub/smart-tab-grouping/.venv/lib/python3.11/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/Users/Rrando/Documents/GitHub/smart-tab-grouping/.venv/lib/python3.11/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/Users/Rrando/Documents/GitHub/smart-tab-grouping/.venv/lib/python3.11/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/Users/Rrando/Documents/GitHub/smart-tab-grouping/.venv/lib/python3.11/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/Users/Rrando/Documents/GitHub/smart-tab-grouping/.venv/lib/python3.11/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "        training_files = TUNING_DATA_PATHS_WITH_NONE\n",
    "        print(f\"Using training files {training_files}\")\n",
    "        datasets = []\n",
    "        for training_file in training_files:\n",
    "            download_bucket_to_file(TAB_GROUPING_BUCKET_NAME, training_file, local_filename)\n",
    "            datasets.append(pd.read_csv(local_filename, keep_default_na=False).fillna(\"\"))\n",
    "        datasets[NOISE_TRAINING_DATA_SET_INDEX] = datasets[NOISE_TRAINING_DATA_SET_INDEX].sample(n=500).reset_index(drop=True)  # reduce number a bit of None set\n",
    "\n",
    "        topic_data = pd.concat(datasets, ignore_index=True).fillna(\"\")\n",
    "        topic_data = topic_data.drop_duplicates(subset=[\"input_titles\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ba79ab1-b5da-47b3-aad9-cdd42bdc574d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "output\n",
       "None                      772\n",
       "Adult Content              30\n",
       "Jewelry                    29\n",
       "Real Estate                27\n",
       "Home Decor                 26\n",
       "                         ... \n",
       "Financial Accounts          1\n",
       "Financial Advice            1\n",
       "Financial Basics            1\n",
       "Financial Education         1\n",
       "iPhone Troubleshooting      1\n",
       "Name: count, Length: 4270, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_data.value_counts(\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d7d4957-1542-4a2b-bbe3-2878d95b5363",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_data[\"output\"] = topic_data.apply(lambda a: a[\"before_none\"] if a[\"before_none\"] else a[\"output\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7fa84dd9-9f21-44fd-9dde-47421ea14b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "output\n",
       "None                      480\n",
       "Adult Content              35\n",
       "Jewelry                    29\n",
       "Local News                 27\n",
       "Real Estate                27\n",
       "                         ... \n",
       "Finance App                 1\n",
       "Finance Documentaries       1\n",
       "Finance Resources           1\n",
       "Finance Trends              1\n",
       "iPhone Troubleshooting      1\n",
       "Name: count, Length: 4448, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_data.value_counts(\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "429cb3ac-63db-4cc8-83d6-27cf99d270d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shorten_boost = 0.08\n",
    "#print(f\"Shortening labels with setting {shorten_boost}\")\n",
    "#stl = ShortenTopicLength(shorten_boost)\n",
    "#topic_data = stl.shorten_topics(topic_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4975c82-584e-4ca6-833c-8777ac77b712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "output\n",
       "None                      480\n",
       "Adult Content              35\n",
       "Jewelry                    29\n",
       "Local News                 27\n",
       "Real Estate                27\n",
       "                         ... \n",
       "Finance App                 1\n",
       "Finance Documentaries       1\n",
       "Finance Resources           1\n",
       "Finance Trends              1\n",
       "iPhone Troubleshooting      1\n",
       "Name: count, Length: 4448, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_data.value_counts(\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f75c4a6-1838-4d2a-84be-cd16feb0a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_data.value_counts(\"output\").to_csv(\"total.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f37b4065-81e9-4450-8be2-c5f9b5ef56c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "output\n",
       "None                      480\n",
       "Adult Content              35\n",
       "Jewelry                    29\n",
       "Local News                 27\n",
       "Real Estate                27\n",
       "                         ... \n",
       "Finance App                 1\n",
       "Finance Documentaries       1\n",
       "Finance Resources           1\n",
       "Finance Trends              1\n",
       "iPhone Troubleshooting      1\n",
       "Name: count, Length: 4448, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_data.value_counts(\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "68ed9b46-5e59-4a03-8fe2-5254a817270f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>input_titles</th>\n",
       "      <th>input_keywords</th>\n",
       "      <th>input_description</th>\n",
       "      <th>output</th>\n",
       "      <th>output_orig</th>\n",
       "      <th>before_none</th>\n",
       "      <th>url</th>\n",
       "      <th>shortened</th>\n",
       "      <th>input_with_prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Episode 16 - The plane show (Preview) - SomeNe...</td>\n",
       "      <td></td>\n",
       "      <td>Steve N Allen and Erich McElroy this week get ...</td>\n",
       "      <td>Podcast Preview</td>\n",
       "      <td>Podcast Preview</td>\n",
       "      <td>Podcast Preview</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Topic from keywords: . titles: \\nEpisode 16 - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>55wordstory: Theme 76 - Map/Maps</td>\n",
       "      <td></td>\n",
       "      <td>From @DayaDarwazaTodo:  Questions everywhere, ...</td>\n",
       "      <td>Creative Writing</td>\n",
       "      <td>Creative Writing</td>\n",
       "      <td>Creative Writing</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Topic from keywords: . titles: \\n55wordstory: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>a Fair Substitute for Heaven: Where Rachel McM...</td>\n",
       "      <td></td>\n",
       "      <td>From Walter's letter to Rilla  as he fights fo...</td>\n",
       "      <td>Personal Blog</td>\n",
       "      <td>Personal Blog</td>\n",
       "      <td>Personal Blog</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Topic from keywords: . titles: \\na Fair Substi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Gravitational Waves | Biotechnology &amp; MedTech</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Science</td>\n",
       "      <td>Science &amp; Technology</td>\n",
       "      <td>Science</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Topic from keywords: . titles: \\nGravitational...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Omega Speedmaster Moonwatch Co-Axial Moonphase...</td>\n",
       "      <td></td>\n",
       "      <td>Omega Speedmaster Moonwatch Co-Axial Moonphase...</td>\n",
       "      <td>Luxury Watches</td>\n",
       "      <td>Luxury Watches</td>\n",
       "      <td>Luxury Watches</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Topic from keywords: . titles: \\nOmega Speedma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6638</th>\n",
       "      <td></td>\n",
       "      <td>95.0</td>\n",
       "      <td>95</td>\n",
       "      <td>instagram privacy settings at DuckDuckGo</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Privacy Settings</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Settings</td>\n",
       "      <td>Topic from keywords: . titles: \\ninstagram pri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6639</th>\n",
       "      <td></td>\n",
       "      <td>96.0</td>\n",
       "      <td>96</td>\n",
       "      <td>furniture stores near me at DuckDuckGo</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Local Furniture Stores</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Furniture Stores</td>\n",
       "      <td>Topic from keywords: . titles: \\nfurniture sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6640</th>\n",
       "      <td></td>\n",
       "      <td>97.0</td>\n",
       "      <td>97</td>\n",
       "      <td>tutorials for photoshop beginners at DuckDuckGo</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Photoshop Tutorials</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Photoshop</td>\n",
       "      <td>Topic from keywords: . titles: \\ntutorials for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6641</th>\n",
       "      <td></td>\n",
       "      <td>98.0</td>\n",
       "      <td>98</td>\n",
       "      <td>tourist attractions in paris - Google Search</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Paris Tourism</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Paris</td>\n",
       "      <td>Topic from keywords: . titles: \\ntourist attra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6642</th>\n",
       "      <td></td>\n",
       "      <td>99.0</td>\n",
       "      <td>99</td>\n",
       "      <td>best smartphones - Google Search</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Smartphone Search</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Search</td>\n",
       "      <td>Topic from keywords: . titles: \\nbest smartpho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6623 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0.2 Unnamed: 0.1  Unnamed: 0  \\\n",
       "0             0.0          0.0           0   \n",
       "1             1.0          1.0           1   \n",
       "2             2.0          2.0           2   \n",
       "3             3.0          3.0           3   \n",
       "4             4.0          4.0           4   \n",
       "...           ...          ...         ...   \n",
       "6638                      95.0          95   \n",
       "6639                      96.0          96   \n",
       "6640                      97.0          97   \n",
       "6641                      98.0          98   \n",
       "6642                      99.0          99   \n",
       "\n",
       "                                           input_titles input_keywords  \\\n",
       "0     Episode 16 - The plane show (Preview) - SomeNe...                  \n",
       "1                      55wordstory: Theme 76 - Map/Maps                  \n",
       "2     a Fair Substitute for Heaven: Where Rachel McM...                  \n",
       "3         Gravitational Waves | Biotechnology & MedTech                  \n",
       "4     Omega Speedmaster Moonwatch Co-Axial Moonphase...                  \n",
       "...                                                 ...            ...   \n",
       "6638           instagram privacy settings at DuckDuckGo                  \n",
       "6639             furniture stores near me at DuckDuckGo                  \n",
       "6640    tutorials for photoshop beginners at DuckDuckGo                  \n",
       "6641       tourist attractions in paris - Google Search                  \n",
       "6642                   best smartphones - Google Search                  \n",
       "\n",
       "                                      input_description  \\\n",
       "0     Steve N Allen and Erich McElroy this week get ...   \n",
       "1     From @DayaDarwazaTodo:  Questions everywhere, ...   \n",
       "2     From Walter's letter to Rilla  as he fights fo...   \n",
       "3                                                         \n",
       "4     Omega Speedmaster Moonwatch Co-Axial Moonphase...   \n",
       "...                                                 ...   \n",
       "6638                                                      \n",
       "6639                                                      \n",
       "6640                                                      \n",
       "6641                                                      \n",
       "6642                                                      \n",
       "\n",
       "                      output           output_orig       before_none url  \\\n",
       "0            Podcast Preview       Podcast Preview   Podcast Preview       \n",
       "1           Creative Writing      Creative Writing  Creative Writing       \n",
       "2              Personal Blog         Personal Blog     Personal Blog       \n",
       "3                    Science  Science & Technology           Science       \n",
       "4             Luxury Watches        Luxury Watches    Luxury Watches       \n",
       "...                      ...                   ...               ...  ..   \n",
       "6638        Privacy Settings                                               \n",
       "6639  Local Furniture Stores                                               \n",
       "6640     Photoshop Tutorials                                               \n",
       "6641           Paris Tourism                                               \n",
       "6642       Smartphone Search                                               \n",
       "\n",
       "             shortened                                  input_with_prompt  \n",
       "0                       Topic from keywords: . titles: \\nEpisode 16 - ...  \n",
       "1                       Topic from keywords: . titles: \\n55wordstory: ...  \n",
       "2                       Topic from keywords: . titles: \\na Fair Substi...  \n",
       "3                       Topic from keywords: . titles: \\nGravitational...  \n",
       "4                       Topic from keywords: . titles: \\nOmega Speedma...  \n",
       "...                ...                                                ...  \n",
       "6638          Settings  Topic from keywords: . titles: \\ninstagram pri...  \n",
       "6639  Furniture Stores  Topic from keywords: . titles: \\nfurniture sto...  \n",
       "6640         Photoshop  Topic from keywords: . titles: \\ntutorials for...  \n",
       "6641             Paris  Topic from keywords: . titles: \\ntourist attra...  \n",
       "6642            Search  Topic from keywords: . titles: \\nbest smartpho...  \n",
       "\n",
       "[6623 rows x 12 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d916eb8d-47fe-4081-bf63-60332141107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/Rrando/Documents/GitHub/smart-tab-grouping/src/jobs\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5950b6a-453e-4f32-a926-3d5d3293bf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0601e32e-ad9a-4d34-9ee0-2f42ff555279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distill_t5 import DistillTopicT5\n",
    "from TuneGenTopicModel import create_trainer_for_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a0b4f3f-64bf-4b90-b074-aa9e80521bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "            {\n",
    "                \"learning_rate\": 5e-3,\n",
    "                \"batch_size\": 8,\n",
    "                \"model_name\": \"google/t5-efficient-tiny\",\n",
    "                \"label_column\": \"output\",\n",
    "                \"use_keywords\": True,\n",
    "                \"single_tab_handling\": False,\n",
    "                \"learning_rate_decay\": False,\n",
    "                \"shorten_training_label_boost\": 0.08,\n",
    "                \"teacher_model_artifact\": \"moso/tab_grouping/model-uxfe87sy:v0\"\n",
    "            }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e09912ab-333f-432b-abec-da413079a1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = create_trainer_for_config(configs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8d7cfff-af82-40c1-a651-256d74387fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SINGLE_TAB_VALIDATION_PATH = \"topic/single_tab_validation.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc70527d-b826-49cc-9e83-5b5a8ff7c9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rrando/Documents/GitHub/smart-tab-grouping/.venv/lib/python3.11/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/Users/Rrando/Documents/GitHub/smart-tab-grouping/.venv/lib/python3.11/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "        validation_data = download_bucket_to_csv(TAB_GROUPING_BUCKET_NAME, SINGLE_TAB_VALIDATION_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef77f42d-588c-46fa-9cdd-63ac3d7bd4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset size 5298\n",
      "Eval Dataset size 1325\n",
      "Validation Dataset size 36\n"
     ]
    }
   ],
   "source": [
    "trainer.setup_data(topic_data, validation_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e5b874e-f2bb-4c0e-abbd-a0227d3da9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd857dedcf5d4d2c93a9f61ee1a1b22a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/62.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b1f3146a-9e1e-4804-a2a8-f0c430e2b853",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    TrainingArguments, Trainer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5c910914-cc57-4b87-ad4c-cc65be5509c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = T5ForConditionalGeneration.from_pretrained(\"google/t5-efficient-tiny\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "29950780-cd70-46c9-9974-83fa95331977",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"google/t5-efficient-tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6e1d6d61-7c6f-473b-80d5-3f226b808a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "77214222-dff2-4858-a837-d806aeec9661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec950a01e104477c9ad8096623a5d52e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5298 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9acc658d1840aa84699ebcb8770ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1325 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "        tokenized_training_dataset = trainer.train_dataset.map(trainer.preprocess_function, batched=True)\n",
    "        tokenized_eval_dataset = trainer.eval_dataset.map(trainer.preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "87085cd9-62a0-474d-86c6-2e254b3faecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c22d7b50e9a94d388d987e3e78d6bb1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5298 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "        def add_decoder_ids(item_input_dict):\n",
    "            decoder_input_ids = teacher_model._shift_right(torch.tensor(item_input_dict[\"labels\"]))\n",
    "            item_input_dict[\"decoder_input_ids\"] = decoder_input_ids\n",
    "            return item_input_dict\n",
    "\n",
    "        tokenized_training_dataset = tokenized_training_dataset.map(add_decoder_ids, batched=True)\n",
    "        tokenized_training_dataset.set_format(\n",
    "            type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\", \"decoder_input_ids\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fe1b801f-c804-432b-a5a3-5d7a6d11549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "            tokenized_training_dataset,\n",
    "            batch_size=4,\n",
    "            shuffle=True,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "668b6e60-6124-4920-bff8-f0da998a97ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in train_loader:\n",
    "    res = teacher_model(**a)\n",
    "    text = teacher_model.generate(a[\"input_ids\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "89a0ad1d-80bb-4359-9953-3c5e3fd369d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples, teacher_model=None):\n",
    "    # Tokenize the input text\n",
    "    inputs = examples[\"input_text\"]\n",
    "    model_inputs = tokenizer(\n",
    "        inputs, \n",
    "        max_length=512, \n",
    "        truncation=True, \n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    if teacher_model is None:\n",
    "        targets = examples[\"target_text\"]\n",
    "        with tokenizer.as_target_tokenizer():\n",
    "            tokenized_targets = tokenizer(\n",
    "                targets, \n",
    "                max_length=64, \n",
    "                truncation=True, \n",
    "                padding=\"max_length\"\n",
    "            )\n",
    "        model_inputs[\"labels\"] = tokenized_targets[\"input_ids\"]\n",
    "    else:\n",
    "        # Generate predictions from teacher and re-tokenize to get padding etc\n",
    "        generated_ids = teacher_model.generate(\n",
    "            tokenizer(inputs, return_tensors=\"pt\", padding=True, truncation=True).input_ids,\n",
    "            max_length=64\n",
    "        )\n",
    "        decoded_outputs = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "        with tokenizer.as_target_tokenizer():\n",
    "            tokenized_labels = tokenizer(\n",
    "                decoded_outputs, \n",
    "                max_length=64, \n",
    "                truncation=True, \n",
    "                padding=\"max_length\"\n",
    "            )\n",
    "        model_inputs[\"labels\"] = tokenized_labels[\"input_ids\"]\n",
    "    model_inputs[\"labels\"] = [\n",
    "            [(token if token != tokenizer.pad_token_id else -100) for token in label_seq]\n",
    "            for label_seq in model_inputs[\"labels\"]\n",
    "        ]\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4040d976-14fc-4a39-a842-86374c8cd0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bf638d3c-394f-4163-827d-6ca4ff81be97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4cb905fe-2961-422c-b990-8f5b31dd5324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "443f3b23ad044c1e96000b2fe69961e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5298 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_training_dataset = trainer.train_dataset.map(partial(preprocess_function, teacher_model=teacher_model), batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "dae6d395-b288-468d-981c-1b1dacc7f019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_text': ['Topic from keywords: . titles: \\nLC/PC duplex with shutter Fiber Optical Adapter - Buy fiber optic coupler, optical fiber adapter, fiber adapter Product on Kewei fiber'],\n",
       " 'target_text': ['Fiber Optic Products'],\n",
       " 'input_ids': [[18059,\n",
       "   45,\n",
       "   12545,\n",
       "   10,\n",
       "   3,\n",
       "   5,\n",
       "   8342,\n",
       "   10,\n",
       "   3,\n",
       "   6480,\n",
       "   87,\n",
       "   4051,\n",
       "   146,\n",
       "   9247,\n",
       "   28,\n",
       "   18094,\n",
       "   22505,\n",
       "   3,\n",
       "   9546,\n",
       "   1489,\n",
       "   3,\n",
       "   14808,\n",
       "   49,\n",
       "   3,\n",
       "   18,\n",
       "   4783,\n",
       "   6433,\n",
       "   18310,\n",
       "   1158,\n",
       "   52,\n",
       "   6,\n",
       "   14171,\n",
       "   6433,\n",
       "   3374,\n",
       "   49,\n",
       "   6,\n",
       "   6433,\n",
       "   3374,\n",
       "   49,\n",
       "   6246,\n",
       "   30,\n",
       "   2566,\n",
       "   1123,\n",
       "   23,\n",
       "   6433,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0]],\n",
       " 'attention_mask': [[1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0]],\n",
       " 'labels': [[1,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100]]}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_training_dataset[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "411a3fea-beae-4904-a1f9-f56ee38db174",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mteacher_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenized_training_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/smart-tab-grouping/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/smart-tab-grouping/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/smart-tab-grouping/.venv/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:1856\u001b[39m, in \u001b[36mT5ForConditionalGeneration.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1853\u001b[39m \u001b[38;5;66;03m# Encode if needed (training, first prediction pass)\u001b[39;00m\n\u001b[32m   1854\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1855\u001b[39m     \u001b[38;5;66;03m# Convert encoder inputs in embeddings if needed\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1856\u001b[39m     encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1857\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1858\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1859\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1860\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1861\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1862\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1863\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1864\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1865\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n\u001b[32m   1866\u001b[39m     encoder_outputs = BaseModelOutput(\n\u001b[32m   1867\u001b[39m         last_hidden_state=encoder_outputs[\u001b[32m0\u001b[39m],\n\u001b[32m   1868\u001b[39m         hidden_states=encoder_outputs[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) > \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1869\u001b[39m         attentions=encoder_outputs[\u001b[32m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) > \u001b[32m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1870\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/smart-tab-grouping/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/smart-tab-grouping/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/smart-tab-grouping/.venv/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:984\u001b[39m, in \u001b[36mT5Stack.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m    980\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    981\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mYou cannot specify both \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr_msg_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33minput_ids and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr_msg_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33minputs_embeds at the same time\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    982\u001b[39m     )\n\u001b[32m    983\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m984\u001b[39m     input_shape = \u001b[43minput_ids\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m()\n\u001b[32m    985\u001b[39m     input_ids = input_ids.view(-\u001b[32m1\u001b[39m, input_shape[-\u001b[32m1\u001b[39m])\n\u001b[32m    986\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mAttributeError\u001b[39m: 'dict' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "teacher_model(tokenized_training_dataset[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ae2326ee-12a9-42ec-abea-aaadb9ad6492",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns ['decoder_input_ids'] not in the dataset. Current columns in the dataset: ['input_text', 'target_text', 'input_ids', 'attention_mask', 'labels']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtokenized_training_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtorch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput_ids\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mattention_mask\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlabels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoder_input_ids\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/smart-tab-grouping/.venv/lib/python3.11/site-packages/datasets/fingerprint.py:442\u001b[39m, in \u001b[36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    438\u001b[39m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[32m    440\u001b[39m \u001b[38;5;66;03m# Call actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[38;5;66;03m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:  \u001b[38;5;66;03m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/smart-tab-grouping/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:2538\u001b[39m, in \u001b[36mDataset.set_format\u001b[39m\u001b[34m(self, type, columns, output_all_columns, **format_kwargs)\u001b[39m\n\u001b[32m   2536\u001b[39m     missing_columns = \u001b[38;5;28mset\u001b[39m(columns) - \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m._data.column_names)\n\u001b[32m   2537\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m missing_columns:\n\u001b[32m-> \u001b[39m\u001b[32m2538\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2539\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mColumns \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(missing_columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in the dataset. Current columns in the dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._data.column_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   2540\u001b[39m         )\n\u001b[32m   2541\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2542\u001b[39m     columns = columns.copy()  \u001b[38;5;66;03m# Ensures modifications made to the list after this call don't cause bugs\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Columns ['decoder_input_ids'] not in the dataset. Current columns in the dataset: ['input_text', 'target_text', 'input_ids', 'attention_mask', 'labels']"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cee7237d-461a-4f4c-9b61-e5cd0a17f087",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmoso-wandb-bot\u001b[0m (\u001b[33mmoso\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c9fdfb1c5242cebe998365d781b3d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011169756946360899, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/Rrando/Documents/GitHub/smart-tab-grouping/notebooks/wandb/run-20250414_091558-yecrzkc9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/moso/tab_grouping_distillation/runs/yecrzkc9' target=\"_blank\">astral-salad-13</a></strong> to <a href='https://wandb.ai/moso/tab_grouping_distillation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/moso/tab_grouping_distillation' target=\"_blank\">https://wandb.ai/moso/tab_grouping_distillation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/moso/tab_grouping_distillation/runs/yecrzkc9' target=\"_blank\">https://wandb.ai/moso/tab_grouping_distillation/runs/yecrzkc9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B Run ID: yecrzkc9\n",
      "W&B Run Name: astral-salad-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-uxfe87sy:v0, 944.47MB. 4 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   4 of 4 files downloaded.  \n",
      "Done. 0:0:3.8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe62d6946f8e46af89bdb5a63246ba62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5306 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rrando/Library/Caches/pypoetry/virtualenvs/mozsocial-ml-services-Hn4MZpip-py3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3921: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf37765e6ea44f2abcef6c6931ae31d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1327 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e664ac7c81846a9abe080ccee63e0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5306 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b64f96958d42bbb7c6cbf169ed7169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   2%|██▏                                                                                      | 16/664 [00:49<33:44,  3.12s/it, loss_value=163]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/smart-tab-grouping/src/jobs/distill_t5.py:166\u001b[0m, in \u001b[0;36mDistillTopicT5.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m     teacher_outputs \u001b[38;5;241m=\u001b[39m teacher_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbatch)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# Forward pass through the student model\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m student_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m student_outputs\u001b[38;5;241m.\u001b[39mlogits\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m teacher_outputs\u001b[38;5;241m.\u001b[39mlogits\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m    168\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_loss(student_outputs, teacher_outputs, batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/mozsocial-ml-services-Hn4MZpip-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/mozsocial-ml-services-Hn4MZpip-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/mozsocial-ml-services-Hn4MZpip-py3.11/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:1705\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# Encode if needed (training, first prediction pass)\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1704\u001b[0m     \u001b[38;5;66;03m# Convert encoder inputs in embeddings if needed\u001b[39;00m\n\u001b[0;32m-> 1705\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n\u001b[1;32m   1715\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1716\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   1717\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1718\u001b[0m         attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1719\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/mozsocial-ml-services-Hn4MZpip-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/mozsocial-ml-services-Hn4MZpip-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/mozsocial-ml-services-Hn4MZpip-py3.11/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:1109\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1094\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1095\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39mforward,\n\u001b[1;32m   1096\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1106\u001b[0m         output_attentions,\n\u001b[1;32m   1107\u001b[0m     )\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1109\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/mozsocial-ml-services-Hn4MZpip-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/mozsocial-ml-services-Hn4MZpip-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/mozsocial-ml-services-Hn4MZpip-py3.11/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:749\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    746\u001b[0m     attention_outputs \u001b[38;5;241m=\u001b[39m attention_outputs \u001b[38;5;241m+\u001b[39m cross_attention_outputs[\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m    748\u001b[0m \u001b[38;5;66;03m# Apply Feed Forward layer\u001b[39;00m\n\u001b[0;32m--> 749\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;66;03m# clamp inf values to enable fp16 training\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hidden_states\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/mozsocial-ml-services-Hn4MZpip-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/mozsocial-ml-services-Hn4MZpip-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/mozsocial-ml-services-Hn4MZpip-py3.11/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:339\u001b[0m, in \u001b[0;36mT5LayerFF.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    337\u001b[0m forwarded_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[1;32m    338\u001b[0m forwarded_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDenseReluDense(forwarded_states)\n\u001b[0;32m--> 339\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforwarded_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/mozsocial-ml-services-Hn4MZpip-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/mozsocial-ml-services-Hn4MZpip-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/mozsocial-ml-services-Hn4MZpip-py3.11/lib/python3.11/site-packages/torch/nn/modules/dropout.py:58\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/mozsocial-ml-services-Hn4MZpip-py3.11/lib/python3.11/site-packages/torch/nn/functional.py:1266\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d88f8e1-a5c2-4357-8af2-f5e01bc19bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_eval_dataset = trainer.eval_dataset.map(trainer.preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de720ce0-bc1b-40b3-8149-c115777c063b",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = tokenized_eval_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb8757b-4521-42ba-af9f-8164026b27f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "            input = item[\"input_text\"]\n",
    "            label = item['target_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b0a78c-bd18-4b83-9886-747c7c1664fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8939407b-7b20-4e71-ac86-80d4051444c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d96587b-8ac2-4c8f-908e-9ff616d48f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "            input_encodings = trainer.tokenizer(input, return_tensors=\"pt\", truncation=True,\n",
    "                                             padding=True)\n",
    "            label_encodings = trainer.tokenizer(label, return_tensors=\"pt\", truncation=True,\n",
    "                                             padding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81a0911-5d89-471d-99fc-34bc38bf86c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1975304e-d4aa-421a-b340-ac82cb950588",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ff07de-d463-4b9d-89ba-82dd8697a99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "                outputs = trainer.model(\n",
    "                    input_ids=input_encodings[\"input_ids\"],\n",
    "                    attention_mask=input_encodings[\"attention_mask\"],\n",
    "                    labels=label_encodings[\"input_ids\"]\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe78caaa-996c-48a2-85d9-161964297428",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f13702b-d60d-4546-8e66-f9a99bd59c73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464b3715-63cb-4367-bafd-5e72df8064e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_gen = trainer.model.generate(input_encodings[\"input_ids\"], max_length=30, num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b521002b-471f-45b6-87fc-a83b70dc8843",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad0ec33-0e48-4faa-8ca3-9f3cb8ccc16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainer.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ee9bc8-5f3c-432b-9d94-1455ea84a4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.config.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7a0dd5-b6f2-4ea8-9d68-7fee448da7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a568487-f8a3-4b5f-986a-1fd9ca8a49fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.run_eval(tokenized_eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4b1967-4b8f-406f-b29f-28083cffef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "   def run_eval(eval_dataset, name=\"Eval\", prefix=None, log_wandb=True):\n",
    "        results_labels = []\n",
    "        results_output = []\n",
    "        losses = []\n",
    "        for item in eval_dataset:\n",
    "            input = item[\"input_text\"]\n",
    "            label = item['target_text']\n",
    "            input_encodings = trainer.tokenizer(input, return_tensors=\"pt\", truncation=True,\n",
    "                                             padding=True)\n",
    "            label_encodings = trainer.tokenizer(label, return_tensors=\"pt\", truncation=True,\n",
    "                                             padding=True)\n",
    "            input_ids = input_encodings[\"input_ids\"]\n",
    "            attention_mask = input_encodings[\"attention_mask\"]\n",
    "            label_ids = label_encodings[\"input_ids\"]\n",
    "            outputs = trainer.model.generate(input_ids, max_length=30, num_return_sequences=1)\n",
    "            print(outputs)\n",
    "            response = trainer.tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f70350b-7f3f-4ebf-9385-19e804122653",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.resize_token_embeddings(len(trainer.tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a401e9f3-4468-417b-98d1-3df2b257bfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_eval(tokenized_eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55136fd7-96c9-46fd-8eb4-3f1c9120074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "        tokenized_eval_dataset = trainer.eval_dataset.map(trainer.preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bed07b-23d1-4c6c-8866-92d71d8f86a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1771a8d9-752b-425f-9f16-6ff1f7544a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project=\"tab_grouping_distillation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c8cd60-64f3-4707-a81e-998a163eb131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    TrainingArguments, Trainer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946521a9-bdda-4af2-9a36-4f7a7fa86915",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact = run.use_artifact(\"moso/tab_grouping/model-uxfe87sy:v0\", type='model')\n",
    "artifact_dir = artifact.download()\n",
    "teacher_model = T5ForConditionalGeneration.from_pretrained(artifact_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b5a349-4d10-4e99-9a2a-3122e1dbb9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_tokenizer = T5Tokenizer.from_pretrained(\"/Users/Rrando/Documents/GitHub/smart-tab-grouping/models/noble-yogurt-330\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18123cc-637c-4f6b-929b-ff7ca75f3e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_tokenizer.encode(\"TEst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdd4249-1eb6-4539-8036-8aef2eb09b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(teacher_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231ac4c9-cf87-46ad-8714-230b1c78c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.tokenizer.encode(\"TEst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01360f95-3b46-4b27-8b69-9781e4082782",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_tokenizer = T5Tokenizer.from_pretrained(\"moso/tab_grouping/model-uxfe87sy:v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e5bc1e-a983-4513-9226-beebed26d647",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainer.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806e84ba-754f-4503-92cf-1a4045dbe40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "        tokenized_eval_dataset = tokenized_eval_dataset.map(add_decoder_ids, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcd11ee-4943-484d-a50f-17e518892859",
   "metadata": {},
   "outputs": [],
   "source": [
    "        def add_decoder_ids(item_input_dict):\n",
    "            decoder_input_ids = teacher_model._shift_right(torch.tensor(item_input_dict[\"labels\"]))\n",
    "            item_input_dict[\"decoder_input_ids\"] = decoder_input_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487ae4c1-9b0c-40c5-87e0-7c57004c10f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f104a82-af67-4861-80df-9dc313477269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26a0526-04d0-409c-ae8c-4bc696d24fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    TrainingArguments, Trainer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a019e675-c0ac-4a80-897c-3a6611411f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "        teacher_model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-small\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858849a6-dc88-495e-bdcb-499be13b0796",
   "metadata": {},
   "outputs": [],
   "source": [
    "            item_input_dict[\"decoder_input_ids\"] = decoder_input_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37da0ae8-2f1d-4e8f-90cf-b5326fa4f123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49800c9-a874-4341-8d28-3e01d047efc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "        def add_decoder_ids(item_input_dict):\n",
    "            decoder_input_ids = teacher_model._shift_right(torch.tensor(item_input_dict[\"labels\"]))\n",
    "            item_input_dict[\"decoder_input_ids\"] = decoder_input_ids\n",
    "            return item_input_dict\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c550d7a-e706-4b97-8a8a-0b35f737ea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "        tokenized_eval_dataset = tokenized_eval_dataset.map(add_decoder_ids, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880e49cd-b1bd-4125-8848-b9a1532aca05",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_eval_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1535ad5-83a7-47f4-bda5-26b66440f311",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
