{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "581755c5-3d91-4c1f-b01e-40d9de375c66",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb473ed7-aa9e-42fd-9446-a081d9ba9c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Rrando/Documents/GitHub/smart-tab-grouping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rrando/Documents/GitHub/smart-tab-grouping/.venv/lib/python3.11/site-packages/IPython/core/magics/osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n",
      "/Users/Rrando/Documents/GitHub/smart-tab-grouping/.venv/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%pwd\n",
    "%cd \"~/Documents/GitHub/smart-tab-grouping\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e80dcd-c61a-4551-81e4-69749de0ad2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d82dbb51-bb12-46c4-b532-87a2735caccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3c8d2f3-2be3-4dc8-9461-9ed71947a0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/individual_tests/private/all_users2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e711a63-5ece-4b73-a757-0cba0548572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51e52356-e47c-4910-863a-bec23e119ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rouge_scores(row, pred_key=None):\n",
    "    scores = scorer.score(row['label'], row[pred_key])\n",
    "    return {\n",
    "        'rouge1': scores['rouge1'].fmeasure,\n",
    "        'rouge2': scores['rouge2'].fmeasure,\n",
    "        'rougeL': scores['rougeL'].fmeasure,\n",
    "        'pred_len': len(row[pred_key]),\n",
    "        'label_len': len(row['label'])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c14856f7-8329-419c-9e2e-1c96a07d3984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rouge_scores(input_df: DataFrame, compare_column: str):\n",
    "    rouge_scores_df = input_df.apply(partial(compute_rouge_scores, pred_key=compare_column) , axis=1, result_type='expand')\n",
    "    average_scores = rouge_scores_df.mean().to_dict()\n",
    "    print(average_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc08ad0e-5750-4823-8181-6b6c58bdb11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/Rrando/Documents/GitHub/smart-tab-grouping/src\")\n",
    "from util.tab_titles import T5TopicGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "477ec933-aae1-45fa-9c9a-01a746b329d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Rrando/Documents/GitHub/smart-tab-grouping\n"
     ]
    }
   ],
   "source": [
    "topic_gen = T5TopicGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "388913c9-0c7a-473c-8581-a8de4502f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_topic_keywords(row, legacy=True):\n",
    "    return topic_gen.get_topic_with_keywords({\"documents\": row[\"three_titles\"].split('\\n'), \"keywords\": row[\"keywords\"].split(',')}, legacy=legacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07b9dd63-1203-4293-b501-03c089b475ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_topic(row):\n",
    "    return topic_gen.get_topic({\"documents\": row[\"three_titles\"].split('\\n')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc64325-9f70-40fc-bca7-b15d4ef028d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9e6e08c-d0d7-482d-a8ed-0f2d37f71a94",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OpenAITopicGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecomputed_titles_keywords\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: compute_topic_keywords(row), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecomputed_title_no_keywords\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: compute_topic(row), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m llm_topic_gen_no_keywords \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAITopicGenerator\u001b[49m(support_keywords\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai_keywords\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: llm_topic_gen_keywords\u001b[38;5;241m.\u001b[39mget_topic({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m\"\u001b[39m: row\u001b[38;5;241m.\u001b[39mthree_titles\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeywords\u001b[39m\u001b[38;5;124m\"\u001b[39m: row\u001b[38;5;241m.\u001b[39mkeywords\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)}), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m print_rouge_scores(df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai_keywords\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'OpenAITopicGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "# Look at OpenAI can do for generating topics from a set of tabs\n",
    "\n",
    "df[\"recomputed_titles_keywords\"] = df.apply(lambda row: compute_topic_keywords(row), axis=1)\n",
    "df[\"recomputed_title_no_keywords\"] = df.apply(lambda row: compute_topic(row), axis=1)\n",
    "llm_topic_gen_no_keywords = OpenAITopicGenerator(support_keywords=False)\n",
    "df[\"openai_keywords\"] = df.apply(lambda row: llm_topic_gen_keywords.get_topic({\"documents\": row.three_titles.split(\"\\n\"), \"keywords\": row.keywords.split(\",\")}), axis=1)\n",
    "print_rouge_scores(df, \"openai_keywords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe273ed6-0c18-499e-ad22-a873dd092c37",
   "metadata": {},
   "source": [
    "Compare with fine tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b262d0aa-af69-4469-81d7-f7c26b0bda4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Rrando/Documents/GitHub/smart-tab-grouping\n",
      "{'rouge1': 0.31388888888888883, 'rouge2': 0.020833333333333332, 'rougeL': 0.31388888888888883, 'pred_len': 7.666666666666667, 'label_len': 11.375}\n"
     ]
    }
   ],
   "source": [
    "topic_gen = T5TopicGenerator(model_name=\"./models/gentle-pyramid-114\")\n",
    "df[\"recomputed_title_keywords_pyramid\"] = df.apply(lambda row: compute_topic_keywords(row, legacy=False), axis=1)\n",
    "print_rouge_scores(df, \"recomputed_title_keywords_pyramid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea39a5a1-328f-4b77-a0c8-bbbe868df903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9af3fd-35e8-4c1e-b8ab-9b464a389e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c18c0aad-d142-44c7-9a37-ca88431d6268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Rrando/Documents/GitHub/smart-tab-grouping\n",
      "{'rouge1': 0.32837301587301587, 'rouge2': 0.07222222222222223, 'rougeL': 0.32837301587301587, 'pred_len': 16.333333333333332, 'label_len': 11.375}\n"
     ]
    }
   ],
   "source": [
    "topic_gen = T5TopicGenerator(model_name=\"./models/cool-yogurt-98\")\n",
    "df[\"recomputed_title_keywords_yogurt\"] = df.apply(lambda row: compute_topic_keywords(row, legacy=False), axis=1)\n",
    "print_rouge_scores(df, \"recomputed_title_keywords_yogurt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6d0ab83-ab60-405a-ba08-02b3923a620a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Rrando/Documents/GitHub/smart-tab-grouping\n",
      "{'rouge1': 0.2859126984126984, 'rouge2': 0.0375, 'rougeL': 0.2859126984126984, 'pred_len': 13.645833333333334, 'label_len': 11.375}\n"
     ]
    }
   ],
   "source": [
    "topic_gen = T5TopicGenerator(model_name=\"./models/swift-rain-107\")\n",
    "df[\"recomputed_title_keywords_rain\"] = df.apply(lambda row: compute_topic_keywords(row, legacy=False), axis=1)\n",
    "print_rouge_scores(df, \"recomputed_title_keywords_rain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff42dc9e-c12c-48a1-be65-503c48a409e6",
   "metadata": {},
   "source": [
    "Look at relative length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef5b570b-056d-46c3-89e6-fd0196517c2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.645833333333334"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"recomputed_title_keywords_rain\"].str.len().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79f23ab8-b34c-4bc8-90ca-7b7346449ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.666666666666667"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"recomputed_title_keywords_pyramid\"].str.len().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f199de-575c-4d9d-82fb-4d5205ba0614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718dc98e-02dd-41c1-b212-5487b9477a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
